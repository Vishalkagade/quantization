{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import the necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision.datasets as datasets \n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.models import resnet18\n",
    "import torch.nn as nn\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "from pathlib import Path\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load the CIFAR dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make torch deterministic\n",
    "_ = torch.manual_seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 170M/170M [00:18<00:00, 9.42MB/s] \n"
     ]
    }
   ],
   "source": [
    "transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.4914, 0.4822, 0.4465), (0.247, 0.243, 0.261))])\n",
    "\n",
    "# Load the MNIST dataset\n",
    "fmnist_trainset = datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)\n",
    "# Create a dataloader for the training\n",
    "train_loader = torch.utils.data.DataLoader(fmnist_trainset, batch_size=10, shuffle=True)\n",
    "\n",
    "# Load the MNIST test set\n",
    "fmnist_testset = datasets.CIFAR10(root='./data', train=False, download=True, transform=transform)\n",
    "test_loader = torch.utils.data.DataLoader(fmnist_testset, batch_size=10, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10, 3, 32, 32]) torch.Size([10])\n"
     ]
    }
   ],
   "source": [
    "#check the size and shape\n",
    "image, label = next(iter(train_loader))\n",
    "classes = fmnist_trainset.classes\n",
    "print(image.shape, label.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [-1.5002179..1.8652618].\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Label: cat')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "idx = 3\n",
    "plt.imshow(image[idx].permute(1,2,0), cmap='gray')\n",
    "plt.title(f'Label: {classes[label[idx].item()]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#lets use a pretrained resnet18 model\n",
    "\n",
    "from torchvision.models import ResNet18_Weights\n",
    "\n",
    "model = resnet18(weights=ResNet18_Weights.IMAGENET1K_V1)\n",
    "# Modify the model to fit the FashionMNIST dataset\n",
    "model.conv1 = nn.Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
    "model.fc = nn.Linear(512, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ResNet(\n",
       "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu): ReLU(inplace=True)\n",
       "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  (layer1): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "  (fc): Linear(in_features=512, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net = model\n",
    "net.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-0.4896, -0.5672, -1.3271, -0.1048,  1.0587, -0.2527, -0.8475,  0.2661,\n",
      "         1.0041,  1.2994], grad_fn=<SelectBackward0>)\n"
     ]
    }
   ],
   "source": [
    "#sanity check\n",
    "image, label = next(iter(train_loader))\n",
    "output = net(image.to(device))\n",
    "print(output[3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1: 100%|██████████| 5000/5000 [16:58<00:00,  4.91it/s, loss=2.05]\n"
     ]
    }
   ],
   "source": [
    "def train(train_loader, net, epochs:int = 5, total_iterations_limit: int = None):\n",
    "    cross_el = nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.Adam(net.parameters(), lr=0.001)\n",
    "\n",
    "    total_iterations = 0\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        net.train()\n",
    "\n",
    "        loss_sum = 0\n",
    "        num_iterations = 0\n",
    "\n",
    "        data_iterator = tqdm(train_loader, desc=f'Epoch {epoch+1}')\n",
    "        if total_iterations_limit is not None:\n",
    "            data_iterator.total = total_iterations_limit\n",
    "        for data in data_iterator:\n",
    "            num_iterations += 1\n",
    "            total_iterations += 1\n",
    "            x, y = data\n",
    "            x = x.to(device)\n",
    "            y = y.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            output = net(x)\n",
    "            loss = cross_el(output, y)\n",
    "            loss_sum += loss.item()\n",
    "            avg_loss = loss_sum / num_iterations\n",
    "            data_iterator.set_postfix(loss=avg_loss)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            if total_iterations_limit is not None and total_iterations >= total_iterations_limit:\n",
    "                return\n",
    "            \n",
    "def print_size_of_model(model):\n",
    "    torch.save(model.state_dict(), \"temp_delme.p\")\n",
    "    print('Size (KB):', os.path.getsize(\"temp_delme.p\")/1e3)\n",
    "    os.remove('temp_delme.p')\n",
    "\n",
    "MODEL_FILENAME = 'cifar.pt'\n",
    "\n",
    "if Path(MODEL_FILENAME).exists():\n",
    "    net.load_state_dict(torch.load(MODEL_FILENAME))\n",
    "    print('Loaded model from disk')\n",
    "else:\n",
    "    train(train_loader, net, epochs=1)\n",
    "    # Save the model to disk\n",
    "    torch.save(net.state_dict(), MODEL_FILENAME)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define the testing loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(model: nn.Module, total_iterations: int = None) -> None:\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    iterations = 0\n",
    "\n",
    "    model.eval()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for data in tqdm(test_loader, desc='Testing'):\n",
    "            x, y = data\n",
    "            x = x.to(device)\n",
    "            y = y.to(device)\n",
    "            output = model(x)\n",
    "            for idx, i in enumerate(output):\n",
    "                if torch.argmax(i) == y[idx]:\n",
    "                    correct +=1\n",
    "                total +=1\n",
    "            iterations += 1\n",
    "            if total_iterations is not None and iterations >= total_iterations:\n",
    "                break\n",
    "    print(f'Accuracy: {round(correct/total, 3)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Print weights and size of the model before quantization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weights before quantization\n",
      "tensor([[[-7.5427e-02,  4.1682e-02,  4.9491e-02,  7.0368e-02,  1.8078e-02,\n",
      "           3.7474e-02,  7.7130e-02],\n",
      "         [ 9.1967e-02,  8.8117e-02, -3.1272e-02,  6.8134e-02,  1.2669e-02,\n",
      "           8.5247e-02,  8.7015e-02],\n",
      "         [ 1.4388e-01,  1.8098e-01,  7.9465e-02,  1.0141e-01,  1.2517e-01,\n",
      "           1.8271e-01,  1.2789e-01],\n",
      "         [-1.3719e-02,  8.2254e-02,  1.2364e-01,  4.9652e-02, -5.0323e-02,\n",
      "           2.7646e-02,  1.0850e-01],\n",
      "         [-9.3617e-02,  1.4663e-03,  4.0007e-03,  6.2510e-03, -1.2005e-01,\n",
      "          -1.4864e-01, -2.2452e-02],\n",
      "         [-1.4286e-01, -1.1743e-01, -1.9753e-01, -3.6660e-02, -3.1365e-02,\n",
      "          -1.6140e-01, -1.2696e-01],\n",
      "         [-2.0908e-02,  1.2107e-02, -1.6775e-01, -5.7777e-03, -9.9790e-02,\n",
      "          -2.5341e-02, -1.6737e-03]],\n",
      "\n",
      "        [[-7.9495e-02, -1.1530e-01, -3.3373e-02, -8.8984e-02, -5.1620e-02,\n",
      "          -1.1861e-01, -8.9330e-02],\n",
      "         [-2.7335e-02, -8.3369e-02, -6.4884e-02, -1.3379e-01, -1.0908e-01,\n",
      "          -3.5216e-02, -3.7474e-02],\n",
      "         [-2.7786e-02, -1.7303e-02, -3.5047e-03,  7.6782e-02,  7.5501e-02,\n",
      "          -6.2413e-02,  1.4197e-02],\n",
      "         [ 6.2045e-02,  8.9820e-02,  3.8104e-02,  8.0596e-02,  6.4673e-02,\n",
      "           9.1275e-03, -4.0020e-02],\n",
      "         [-1.9180e-01, -1.0556e-01, -4.7932e-02, -3.6820e-02, -1.4404e-01,\n",
      "          -1.5990e-01, -8.9220e-02],\n",
      "         [-2.6114e-01, -2.1674e-01, -1.8506e-01, -2.0695e-01, -9.9477e-02,\n",
      "          -1.7275e-01, -1.5105e-01],\n",
      "         [-6.2258e-02, -6.0963e-02, -1.2486e-01, -1.2516e-01, -1.3706e-01,\n",
      "          -1.4304e-01, -1.5859e-01]],\n",
      "\n",
      "        [[-1.0707e-02, -3.7871e-02, -9.3071e-02,  2.3987e-02, -4.9608e-02,\n",
      "          -3.3142e-02, -1.4962e-03],\n",
      "         [ 7.7286e-02, -6.6822e-02,  2.3649e-02, -7.7798e-02, -6.6982e-02,\n",
      "          -1.7099e-02, -2.3264e-04],\n",
      "         [-6.1598e-03, -2.8337e-02,  6.8177e-02,  7.2719e-02,  1.3258e-02,\n",
      "          -2.2779e-02, -5.1407e-02],\n",
      "         [ 2.1940e-02,  1.3398e-01,  4.7700e-02,  1.2081e-01,  7.1134e-02,\n",
      "           7.1124e-02,  2.8651e-02],\n",
      "         [ 8.9631e-02,  1.2394e-01,  1.6962e-03,  4.3491e-02,  1.0741e-01,\n",
      "           4.2255e-02,  7.9982e-02],\n",
      "         [-7.2844e-02, -7.6573e-02, -1.0439e-02,  4.1309e-02,  4.5095e-02,\n",
      "           3.6017e-02,  5.6098e-02],\n",
      "         [ 8.5669e-02, -3.1471e-02,  6.3548e-02, -2.1835e-02,  2.2453e-02,\n",
      "           4.8234e-03, -7.7002e-03]]], grad_fn=<SelectBackward0>)\n",
      "torch.float32\n"
     ]
    }
   ],
   "source": [
    "# Print the weights matrix of the model before quantization\n",
    "print('Weights before quantization')\n",
    "print(net.conv1.weight[0])\n",
    "print(net.conv1.weight.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of the model before quantization\n",
      "Size (KB): 44804.427\n"
     ]
    }
   ],
   "source": [
    "print('Size of the model before quantization')\n",
    "print_size_of_model(net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the model before quantization: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing: 100%|██████████| 1000/1000 [00:16<00:00, 61.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.357\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "print('Accuracy of the model before quantization: ')\n",
    "test(net)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Apply the quantization observers and config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.ao.quantization.quantize_fx import prepare_fx, convert_fx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kagad\\AppData\\Local\\Temp\\ipykernel_14800\\3638247298.py:4: DeprecationWarning: torch.ao.quantization is deprecated and will be removed in 2.10. \n",
      "For migrations of users: \n",
      "1. Eager mode quantization (torch.ao.quantization.quantize, torch.ao.quantization.quantize_dynamic), please migrate to use torchao eager mode quantize_ API instead \n",
      "2. FX graph mode quantization (torch.ao.quantization.quantize_fx.prepare_fx,torch.ao.quantization.quantize_fx.convert_fx, please migrate to use torchao pt2e quantization API instead (prepare_pt2e, convert_pt2e) \n",
      "3. pt2e quantization has been migrated to torchao (https://github.com/pytorch/ao/tree/main/torchao/quantization/pt2e) \n",
      "see https://github.com/pytorch/ao/issues/2259 for more details\n",
      "  model_prepared = prepare_fx(net, {'': qconfig}, example_input) # prepare the model for quantization\n",
      "c:\\Users\\kagad\\quantization\\.venv\\Lib\\site-packages\\torch\\ao\\quantization\\quantize_fx.py:146: FutureWarning: Passing a QConfig dictionary to prepare is deprecated and will not be supported in a future version. Please pass in a QConfigMapping instead.\n",
      "  prepared = prepare(\n",
      "c:\\Users\\kagad\\quantization\\.venv\\Lib\\site-packages\\torch\\ao\\quantization\\observer.py:246: UserWarning: Please use quant_min and quant_max to specify the range for observers.                     reduce_range will be deprecated in a future release of PyTorch.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GraphModule(\n",
       "  (activation_post_process_0): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (conv1): ConvReLU2d(\n",
       "    (0): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3))\n",
       "    (1): ReLU(inplace=True)\n",
       "  )\n",
       "  (activation_post_process_1): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  (activation_post_process_2): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (layer1): Module(\n",
       "    (0): Module(\n",
       "      (conv1): ConvReLU2d(\n",
       "        (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (1): ReLU(inplace=True)\n",
       "      )\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (1): Module(\n",
       "      (conv1): ConvReLU2d(\n",
       "        (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (1): ReLU(inplace=True)\n",
       "      )\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (activation_post_process_3): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_4): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_5): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_6): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_7): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_8): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (layer2): Module(\n",
       "    (0): Module(\n",
       "      (conv1): ConvReLU2d(\n",
       "        (0): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        (1): ReLU(inplace=True)\n",
       "      )\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (downsample): Module(\n",
       "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2))\n",
       "      )\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (1): Module(\n",
       "      (conv1): ConvReLU2d(\n",
       "        (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (1): ReLU(inplace=True)\n",
       "      )\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (activation_post_process_9): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_10): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_11): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_12): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_13): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_14): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_15): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (layer3): Module(\n",
       "    (0): Module(\n",
       "      (conv1): ConvReLU2d(\n",
       "        (0): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        (1): ReLU(inplace=True)\n",
       "      )\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (downsample): Module(\n",
       "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2))\n",
       "      )\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (1): Module(\n",
       "      (conv1): ConvReLU2d(\n",
       "        (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (1): ReLU(inplace=True)\n",
       "      )\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (activation_post_process_16): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_17): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_18): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_19): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_20): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_21): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_22): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (layer4): Module(\n",
       "    (0): Module(\n",
       "      (conv1): ConvReLU2d(\n",
       "        (0): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        (1): ReLU(inplace=True)\n",
       "      )\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (downsample): Module(\n",
       "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2))\n",
       "      )\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (1): Module(\n",
       "      (conv1): ConvReLU2d(\n",
       "        (0): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (1): ReLU(inplace=True)\n",
       "      )\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (activation_post_process_23): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_24): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_25): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_26): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_27): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_28): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_29): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "  (activation_post_process_30): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_31): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (fc): Linear(in_features=512, out_features=10, bias=True)\n",
       "  (activation_post_process_32): HistogramObserver(min_val=inf, max_val=-inf)\n",
       ")"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example_input = torch.randn(1, 1, 28, 28) # dummy input for quantization\n",
    "torch.backends.quantized.engine = 'fbgemm' # change it for 'fbgemm' if you want to use that backend\n",
    "qconfig = torch.ao.quantization.get_default_qconfig(torch.backends.quantized.engine) # define the backend configuration\n",
    "model_prepared = prepare_fx(net, {'': qconfig}, example_input) # prepare the model for quantization\n",
    "model_prepared.eval()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run a few iterations to calibrate the model\n",
    "with torch.inference_mode():\n",
    "    for i, (x, _) in enumerate(train_loader):\n",
    "        model_prepared(x.to(device))\n",
    "        if i >= 20:\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kagad\\AppData\\Local\\Temp\\ipykernel_14800\\3654225041.py:2: DeprecationWarning: torch.ao.quantization is deprecated and will be removed in 2.10. \n",
      "For migrations of users: \n",
      "1. Eager mode quantization (torch.ao.quantization.quantize, torch.ao.quantization.quantize_dynamic), please migrate to use torchao eager mode quantize_ API instead \n",
      "2. FX graph mode quantization (torch.ao.quantization.quantize_fx.prepare_fx,torch.ao.quantization.quantize_fx.convert_fx, please migrate to use torchao pt2e quantization API instead (prepare_pt2e, convert_pt2e) \n",
      "3. pt2e quantization has been migrated to torchao (https://github.com/pytorch/ao/tree/main/torchao/quantization/pt2e) \n",
      "see https://github.com/pytorch/ao/issues/2259 for more details\n",
      "  model_quantized = convert_fx(model_prepared).eval().to(device)\n"
     ]
    }
   ],
   "source": [
    "# Convert the prepared model to a quantized model\n",
    "model_quantized = convert_fx(model_prepared).eval().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model_quantized.state_dict(), \"model_quantized.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Check statistics of the various layers\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GraphModule(\n",
       "  (conv1): QuantizedConvReLU2d(3, 64, kernel_size=(7, 7), stride=(2, 2), scale=0.018478740006685257, zero_point=0, padding=(3, 3))\n",
       "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  (layer1): Module(\n",
       "    (0): Module(\n",
       "      (conv1): QuantizedConvReLU2d(64, 64, kernel_size=(3, 3), stride=(1, 1), scale=0.014592686668038368, zero_point=0, padding=(1, 1))\n",
       "      (conv2): QuantizedConv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), scale=0.03706875815987587, zero_point=71, padding=(1, 1))\n",
       "    )\n",
       "    (1): Module(\n",
       "      (conv1): QuantizedConvReLU2d(64, 64, kernel_size=(3, 3), stride=(1, 1), scale=0.012502055615186691, zero_point=0, padding=(1, 1))\n",
       "      (conv2): QuantizedConv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), scale=0.048595819622278214, zero_point=58, padding=(1, 1))\n",
       "    )\n",
       "  )\n",
       "  (layer2): Module(\n",
       "    (0): Module(\n",
       "      (conv1): QuantizedConvReLU2d(64, 128, kernel_size=(3, 3), stride=(2, 2), scale=0.018113598227500916, zero_point=0, padding=(1, 1))\n",
       "      (conv2): QuantizedConv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), scale=0.057594314217567444, zero_point=69, padding=(1, 1))\n",
       "      (downsample): Module(\n",
       "        (0): QuantizedConv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), scale=0.04068204015493393, zero_point=56)\n",
       "      )\n",
       "    )\n",
       "    (1): Module(\n",
       "      (conv1): QuantizedConvReLU2d(128, 128, kernel_size=(3, 3), stride=(1, 1), scale=0.02638130821287632, zero_point=0, padding=(1, 1))\n",
       "      (conv2): QuantizedConv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), scale=0.09700353443622589, zero_point=77, padding=(1, 1))\n",
       "    )\n",
       "  )\n",
       "  (layer3): Module(\n",
       "    (0): Module(\n",
       "      (conv1): QuantizedConvReLU2d(128, 256, kernel_size=(3, 3), stride=(2, 2), scale=0.04086965322494507, zero_point=0, padding=(1, 1))\n",
       "      (conv2): QuantizedConv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), scale=0.06825250387191772, zero_point=49, padding=(1, 1))\n",
       "      (downsample): Module(\n",
       "        (0): QuantizedConv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), scale=0.02892061322927475, zero_point=61)\n",
       "      )\n",
       "    )\n",
       "    (1): Module(\n",
       "      (conv1): QuantizedConvReLU2d(256, 256, kernel_size=(3, 3), stride=(1, 1), scale=0.04155366122722626, zero_point=0, padding=(1, 1))\n",
       "      (conv2): QuantizedConv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), scale=0.14933539927005768, zero_point=67, padding=(1, 1))\n",
       "    )\n",
       "  )\n",
       "  (layer4): Module(\n",
       "    (0): Module(\n",
       "      (conv1): QuantizedConvReLU2d(256, 512, kernel_size=(3, 3), stride=(2, 2), scale=0.02735830843448639, zero_point=0, padding=(1, 1))\n",
       "      (conv2): QuantizedConv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), scale=0.2118835747241974, zero_point=73, padding=(1, 1))\n",
       "      (downsample): Module(\n",
       "        (0): QuantizedConv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), scale=0.05834955349564552, zero_point=76)\n",
       "      )\n",
       "    )\n",
       "    (1): Module(\n",
       "      (conv1): QuantizedConvReLU2d(512, 512, kernel_size=(3, 3), stride=(1, 1), scale=0.12266597896814346, zero_point=0, padding=(1, 1))\n",
       "      (conv2): QuantizedConv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), scale=1.7472857236862183, zero_point=61, padding=(1, 1))\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "  (fc): QuantizedLinear(in_features=512, out_features=10, scale=0.8836716413497925, zero_point=103, qscheme=torch.per_channel_affine)\n",
       ")"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(f'Check statistics of the various layers')\n",
    "model_quantized"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compare the dequantized weights and the original weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original weights: \n",
      "Parameter containing:\n",
      "tensor([[[[-7.5427e-02,  4.1682e-02,  4.9491e-02,  ...,  1.8078e-02,\n",
      "            3.7474e-02,  7.7130e-02],\n",
      "          [ 9.1967e-02,  8.8117e-02, -3.1272e-02,  ...,  1.2669e-02,\n",
      "            8.5247e-02,  8.7015e-02],\n",
      "          [ 1.4388e-01,  1.8098e-01,  7.9465e-02,  ...,  1.2517e-01,\n",
      "            1.8271e-01,  1.2789e-01],\n",
      "          ...,\n",
      "          [-9.3617e-02,  1.4663e-03,  4.0007e-03,  ..., -1.2005e-01,\n",
      "           -1.4864e-01, -2.2452e-02],\n",
      "          [-1.4286e-01, -1.1743e-01, -1.9753e-01,  ..., -3.1365e-02,\n",
      "           -1.6140e-01, -1.2696e-01],\n",
      "          [-2.0908e-02,  1.2107e-02, -1.6775e-01,  ..., -9.9790e-02,\n",
      "           -2.5341e-02, -1.6737e-03]],\n",
      "\n",
      "         [[-7.9495e-02, -1.1530e-01, -3.3373e-02,  ..., -5.1620e-02,\n",
      "           -1.1861e-01, -8.9330e-02],\n",
      "          [-2.7335e-02, -8.3369e-02, -6.4884e-02,  ..., -1.0908e-01,\n",
      "           -3.5216e-02, -3.7474e-02],\n",
      "          [-2.7786e-02, -1.7303e-02, -3.5047e-03,  ...,  7.5501e-02,\n",
      "           -6.2413e-02,  1.4197e-02],\n",
      "          ...,\n",
      "          [-1.9180e-01, -1.0556e-01, -4.7932e-02,  ..., -1.4404e-01,\n",
      "           -1.5990e-01, -8.9220e-02],\n",
      "          [-2.6114e-01, -2.1674e-01, -1.8506e-01,  ..., -9.9477e-02,\n",
      "           -1.7275e-01, -1.5105e-01],\n",
      "          [-6.2258e-02, -6.0963e-02, -1.2486e-01,  ..., -1.3706e-01,\n",
      "           -1.4304e-01, -1.5859e-01]],\n",
      "\n",
      "         [[-1.0707e-02, -3.7871e-02, -9.3071e-02,  ..., -4.9608e-02,\n",
      "           -3.3142e-02, -1.4962e-03],\n",
      "          [ 7.7286e-02, -6.6822e-02,  2.3649e-02,  ..., -6.6982e-02,\n",
      "           -1.7099e-02, -2.3264e-04],\n",
      "          [-6.1598e-03, -2.8337e-02,  6.8177e-02,  ...,  1.3258e-02,\n",
      "           -2.2779e-02, -5.1407e-02],\n",
      "          ...,\n",
      "          [ 8.9631e-02,  1.2394e-01,  1.6962e-03,  ...,  1.0741e-01,\n",
      "            4.2255e-02,  7.9982e-02],\n",
      "          [-7.2844e-02, -7.6573e-02, -1.0439e-02,  ...,  4.5095e-02,\n",
      "            3.6017e-02,  5.6098e-02],\n",
      "          [ 8.5669e-02, -3.1471e-02,  6.3548e-02,  ...,  2.2453e-02,\n",
      "            4.8234e-03, -7.7002e-03]]],\n",
      "\n",
      "\n",
      "        [[[-1.7660e-02,  4.7115e-02,  2.9090e-02,  ..., -1.7927e-02,\n",
      "            4.9303e-02,  9.6331e-02],\n",
      "          [ 1.2263e-03,  9.9615e-02,  9.6424e-02,  ...,  9.5341e-02,\n",
      "           -4.4274e-02,  3.1824e-02],\n",
      "          [ 3.4209e-02,  7.9047e-03,  7.9027e-02,  ...,  1.1541e-01,\n",
      "           -1.3764e-03,  4.3301e-02],\n",
      "          ...,\n",
      "          [-1.3326e-02,  9.8165e-02, -1.3698e-02,  ...,  4.1660e-02,\n",
      "            7.8799e-02,  3.5479e-02],\n",
      "          [-1.8904e-02,  3.7288e-03,  5.9818e-02,  ..., -4.6857e-03,\n",
      "            1.0443e-01, -4.7940e-02],\n",
      "          [-3.9673e-02,  5.5443e-02,  1.0591e-01,  ...,  4.2123e-02,\n",
      "            8.0111e-02, -3.9779e-03]],\n",
      "\n",
      "         [[ 2.7128e-02, -9.3892e-04, -2.4123e-02,  ...,  5.8642e-02,\n",
      "            4.1354e-02, -3.9348e-02],\n",
      "          [ 4.1936e-02, -3.7872e-02,  1.1159e-02,  ..., -3.0462e-02,\n",
      "            2.0901e-02,  1.9075e-02],\n",
      "          [ 5.5935e-02, -2.4530e-02,  5.0576e-02,  ..., -5.2554e-02,\n",
      "            7.9277e-02, -1.6620e-02],\n",
      "          ...,\n",
      "          [ 5.3676e-02, -8.7675e-02,  7.0317e-02,  ..., -2.3092e-03,\n",
      "           -8.8833e-03,  6.7017e-02],\n",
      "          [ 8.2120e-02, -8.3021e-02, -3.8631e-02,  ...,  1.2918e-02,\n",
      "           -2.6405e-02,  3.5357e-02],\n",
      "          [ 3.8520e-02, -6.3546e-02,  4.1570e-02,  ...,  5.2256e-02,\n",
      "           -2.7348e-02,  9.6887e-02]],\n",
      "\n",
      "         [[ 2.0474e-02,  5.3171e-03,  1.3480e-01,  ...,  3.1428e-02,\n",
      "            9.8023e-02,  9.3118e-02],\n",
      "          [ 7.7393e-02,  8.8400e-02,  5.0714e-02,  ...,  5.2730e-02,\n",
      "            1.0662e-01,  1.1304e-01],\n",
      "          [ 8.1540e-02,  1.3075e-01,  9.0217e-02,  ...,  1.1769e-01,\n",
      "            9.6608e-02,  1.8362e-02],\n",
      "          ...,\n",
      "          [ 7.0731e-02,  1.0541e-01,  1.4863e-01,  ...,  6.5265e-02,\n",
      "            1.6018e-01,  7.9299e-02],\n",
      "          [ 1.1802e-01,  9.6788e-02,  5.1246e-02,  ...,  1.1550e-01,\n",
      "            7.5054e-02,  1.3317e-01],\n",
      "          [ 2.2770e-02, -5.2734e-03,  1.0502e-01,  ...,  1.2693e-01,\n",
      "            5.7112e-02,  1.0460e-01]]],\n",
      "\n",
      "\n",
      "        [[[-2.8241e-02,  1.5907e-02,  6.8772e-02,  ...,  4.5682e-02,\n",
      "            4.0725e-02,  7.1883e-02],\n",
      "          [-6.9791e-03,  5.8869e-02,  4.9849e-02,  ..., -7.1542e-02,\n",
      "           -3.2871e-02, -3.8456e-03],\n",
      "          [-7.0599e-02,  2.4494e-02,  2.9478e-02,  ..., -8.0476e-02,\n",
      "           -6.4001e-02, -5.4762e-02],\n",
      "          ...,\n",
      "          [ 3.9582e-02,  3.2823e-02, -5.0397e-02,  ..., -5.0246e-02,\n",
      "           -8.7804e-03,  4.0354e-02],\n",
      "          [ 4.1702e-02, -4.5960e-02, -2.9543e-02,  ...,  6.0448e-02,\n",
      "           -4.4919e-02, -2.8785e-02],\n",
      "          [-6.8468e-02, -6.0484e-02,  5.0169e-02,  ..., -5.4448e-02,\n",
      "            6.3036e-02, -3.2857e-03]],\n",
      "\n",
      "         [[-4.2099e-02,  3.3154e-02,  4.1269e-02,  ..., -6.0900e-02,\n",
      "           -7.0937e-02,  8.0143e-02],\n",
      "          [ 7.4044e-02,  7.6268e-02,  2.6321e-03,  ..., -1.3686e-02,\n",
      "            2.3306e-02,  6.7540e-02],\n",
      "          [ 6.0918e-03, -6.2789e-02, -7.7764e-02,  ..., -4.8773e-02,\n",
      "            7.4578e-02, -1.2171e-02],\n",
      "          ...,\n",
      "          [ 1.1671e-02,  5.1630e-02, -2.5698e-02,  ...,  7.8991e-02,\n",
      "           -3.8136e-02,  3.3216e-02],\n",
      "          [ 1.2825e-03, -7.3811e-02,  6.1023e-02,  ...,  4.1764e-02,\n",
      "            7.2710e-03,  8.0380e-03],\n",
      "          [-5.0238e-02, -3.8575e-03,  7.2349e-02,  ...,  3.4779e-02,\n",
      "            5.6743e-02, -6.2124e-02]],\n",
      "\n",
      "         [[ 6.0982e-02, -2.5428e-02, -6.3389e-02,  ...,  7.1419e-03,\n",
      "            1.5789e-02,  2.4241e-02],\n",
      "          [-6.0166e-02, -7.5434e-02,  7.8778e-02,  ..., -6.5021e-02,\n",
      "           -6.4082e-02,  1.6302e-02],\n",
      "          [-6.1460e-02,  4.0818e-02,  7.6647e-02,  ...,  4.5888e-02,\n",
      "            7.1135e-02,  5.2967e-02],\n",
      "          ...,\n",
      "          [ 2.1691e-02, -3.7561e-02, -6.3105e-02,  ...,  1.3720e-02,\n",
      "           -4.5873e-02, -3.4403e-02],\n",
      "          [-4.7437e-02,  3.5016e-02, -1.4905e-02,  ..., -2.0913e-02,\n",
      "            4.1004e-02,  6.0185e-02],\n",
      "          [ 2.4723e-02, -2.8645e-02, -3.9844e-02,  ..., -9.7625e-03,\n",
      "           -7.6513e-02,  4.2904e-02]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[-6.0788e-02, -6.8266e-02, -8.4924e-03,  ...,  2.8018e-02,\n",
      "           -1.0469e-01, -8.2686e-02],\n",
      "          [ 5.8603e-02,  4.6206e-02,  1.6037e-02,  ..., -8.0312e-03,\n",
      "            5.5731e-03, -5.5025e-02],\n",
      "          [ 4.4730e-02,  3.2345e-02, -8.2103e-02,  ..., -7.7103e-02,\n",
      "            2.2824e-02,  7.5093e-03],\n",
      "          ...,\n",
      "          [-5.3419e-02, -6.3104e-03,  2.3019e-02,  ..., -8.4576e-04,\n",
      "            3.2027e-02, -3.4859e-03],\n",
      "          [ 5.3864e-02,  3.0512e-02, -6.6213e-02,  ..., -4.0939e-02,\n",
      "           -8.4289e-02, -9.7566e-02],\n",
      "          [-6.0714e-02,  2.8220e-02, -4.0240e-02,  ..., -1.4207e-01,\n",
      "           -7.5221e-03, -7.5872e-02]],\n",
      "\n",
      "         [[ 1.0509e-02,  2.9345e-02, -3.7522e-03,  ..., -3.1622e-02,\n",
      "           -1.2153e-01, -1.0798e-01],\n",
      "          [-6.8539e-02,  4.7169e-02, -7.6614e-02,  ...,  2.4897e-02,\n",
      "            3.6942e-02,  7.1268e-02],\n",
      "          [ 2.7021e-02,  3.5689e-02, -9.6821e-02,  ..., -5.2105e-02,\n",
      "           -9.0806e-02,  2.7968e-02],\n",
      "          ...,\n",
      "          [-4.1412e-02,  4.6113e-02,  8.8673e-03,  ..., -4.7634e-02,\n",
      "           -4.2164e-02,  5.1704e-02],\n",
      "          [-8.2054e-02, -7.0479e-02,  2.8845e-02,  ..., -3.4452e-02,\n",
      "           -9.4882e-02, -6.6889e-02],\n",
      "          [ 5.8748e-03, -3.0852e-02, -3.7881e-02,  ..., -1.9673e-02,\n",
      "           -9.9662e-02, -6.6638e-02]],\n",
      "\n",
      "         [[ 5.2979e-02,  5.8530e-02, -6.1568e-02,  ..., -2.5254e-02,\n",
      "           -8.6910e-02, -2.5477e-02],\n",
      "          [ 1.2480e-01,  7.1922e-02,  1.6982e-01,  ...,  1.6127e-01,\n",
      "            1.6427e-01,  7.8812e-02],\n",
      "          [ 9.5344e-02,  1.7255e-01,  1.1417e-01,  ...,  2.5359e-02,\n",
      "            6.6767e-02,  1.2698e-01],\n",
      "          ...,\n",
      "          [ 1.4661e-01,  6.5974e-02,  5.0656e-02,  ...,  6.7052e-02,\n",
      "            7.8747e-02,  1.1386e-01],\n",
      "          [ 1.2272e-01,  8.8942e-02,  1.2305e-01,  ...,  7.8279e-02,\n",
      "            3.4539e-02,  7.2733e-02],\n",
      "          [-2.5168e-02,  6.7824e-02,  3.3884e-02,  ...,  3.9804e-02,\n",
      "            8.5820e-02,  3.7321e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 6.3027e-02,  1.2777e-01,  1.5226e-01,  ...,  8.9029e-02,\n",
      "            5.1700e-02,  7.7842e-03],\n",
      "          [ 1.3099e-01,  5.7668e-02,  1.4005e-01,  ...,  1.3342e-01,\n",
      "            5.2284e-02,  9.4833e-02],\n",
      "          [ 1.6224e-02,  1.4036e-01,  1.5983e-01,  ...,  9.3797e-02,\n",
      "            1.4107e-01,  7.7114e-02],\n",
      "          ...,\n",
      "          [ 9.7030e-02,  1.8507e-02,  4.9742e-02,  ..., -1.6682e-02,\n",
      "            1.4128e-01,  4.5738e-02],\n",
      "          [-1.1875e-01, -7.8139e-02, -4.5628e-02,  ..., -1.8021e-02,\n",
      "           -4.2161e-02,  6.7777e-02],\n",
      "          [-3.1500e-02,  3.6543e-02,  3.6283e-02,  ..., -4.9300e-02,\n",
      "            5.3218e-02,  6.1332e-04]],\n",
      "\n",
      "         [[ 6.0422e-02,  5.2466e-02,  1.3949e-02,  ..., -3.8712e-02,\n",
      "            8.7504e-02,  2.4778e-02],\n",
      "          [ 3.1300e-02,  3.3494e-03,  1.3640e-02,  ..., -7.7833e-03,\n",
      "           -2.2745e-02,  9.7729e-03],\n",
      "          [-4.6493e-02,  3.7643e-02,  2.4111e-02,  ...,  5.7239e-02,\n",
      "            6.6298e-02,  6.1179e-02],\n",
      "          ...,\n",
      "          [-4.0498e-02,  8.5681e-02, -4.8467e-02,  ..., -2.9427e-02,\n",
      "            8.9917e-02, -5.0055e-02],\n",
      "          [-2.3271e-02,  1.7213e-02,  4.6557e-02,  ..., -5.6050e-02,\n",
      "           -1.0146e-02, -6.1459e-02],\n",
      "          [-9.6506e-02, -1.5664e-02, -2.3362e-02,  ..., -4.1051e-02,\n",
      "           -1.1116e-02,  2.8914e-03]],\n",
      "\n",
      "         [[-2.8318e-02, -1.6382e-02,  1.0229e-02,  ...,  1.1011e-02,\n",
      "           -4.3757e-02,  3.4947e-02],\n",
      "          [ 3.2292e-02,  1.6762e-03, -5.2340e-02,  ..., -3.7770e-02,\n",
      "            5.7583e-02,  6.4953e-02],\n",
      "          [ 3.7112e-02,  1.1031e-02, -4.3399e-02,  ...,  4.1048e-02,\n",
      "            2.7232e-02, -7.5560e-03],\n",
      "          ...,\n",
      "          [ 8.7590e-02, -2.5191e-02, -9.2728e-03,  ..., -1.5363e-02,\n",
      "            5.5319e-02, -2.1909e-02],\n",
      "          [ 1.1683e-02,  2.7527e-03, -1.1374e-01,  ...,  8.2328e-03,\n",
      "            2.0903e-02, -1.8074e-02],\n",
      "          [ 3.9288e-02, -5.0492e-02, -6.0674e-02,  ..., -3.8749e-02,\n",
      "            4.8558e-02, -4.7271e-02]]],\n",
      "\n",
      "\n",
      "        [[[-7.5096e-02, -9.1178e-02, -3.5333e-02,  ..., -7.9371e-02,\n",
      "           -1.2908e-01, -5.3247e-02],\n",
      "          [-2.4091e-02,  1.5733e-02, -3.6949e-02,  ..., -5.5920e-02,\n",
      "           -1.4650e-01, -9.3437e-02],\n",
      "          [-7.0694e-02, -4.7519e-02, -6.5104e-02,  ..., -1.5966e-01,\n",
      "           -8.3385e-02, -5.8454e-02],\n",
      "          ...,\n",
      "          [ 1.2613e-02, -1.2810e-01, -1.4641e-01,  ..., -1.7936e-02,\n",
      "           -8.5832e-02, -8.2749e-02],\n",
      "          [-1.0204e-01, -2.9823e-02, -5.5745e-03,  ..., -1.2958e-01,\n",
      "           -1.1810e-01, -2.2904e-02],\n",
      "          [-5.0593e-02,  1.0627e-02, -1.1152e-01,  ...,  1.9406e-02,\n",
      "           -7.3458e-02, -6.6612e-02]],\n",
      "\n",
      "         [[ 8.9613e-02, -1.8070e-02,  9.1056e-02,  ..., -7.8537e-02,\n",
      "           -1.7134e-02, -9.2212e-02],\n",
      "          [ 2.3934e-02,  1.0202e-01,  1.2447e-02,  ..., -1.0306e-03,\n",
      "           -3.4282e-02,  1.0480e-02],\n",
      "          [ 4.5404e-02,  1.9225e-02, -2.0784e-02,  ..., -1.4111e-01,\n",
      "           -1.5400e-01,  3.1064e-04],\n",
      "          ...,\n",
      "          [-9.8520e-02, -8.3015e-02, -8.5474e-02,  ...,  1.8410e-02,\n",
      "           -8.2239e-03,  5.0739e-02],\n",
      "          [ 3.2978e-02, -9.8545e-02,  1.7167e-02,  ..., -7.9379e-02,\n",
      "           -5.0812e-02,  2.6063e-02],\n",
      "          [-2.3664e-02,  3.2259e-03,  3.3606e-02,  ..., -4.2123e-03,\n",
      "            3.3324e-02, -2.3689e-02]],\n",
      "\n",
      "         [[-5.0667e-02, -6.8383e-02, -2.8290e-02,  ..., -2.4053e-02,\n",
      "           -7.1262e-02,  4.5131e-02],\n",
      "          [ 5.6647e-02, -5.3504e-02,  7.7046e-02,  ..., -5.1969e-02,\n",
      "            4.6101e-02, -8.6388e-02],\n",
      "          [ 7.3030e-02, -4.4895e-02, -6.5042e-02,  ...,  4.9198e-03,\n",
      "            3.0927e-02, -6.3934e-02],\n",
      "          ...,\n",
      "          [-3.8085e-02, -2.7453e-02, -3.9028e-02,  ..., -8.2013e-02,\n",
      "            4.1984e-03,  8.6951e-03],\n",
      "          [-6.8679e-02, -6.1169e-02, -3.5594e-02,  ...,  1.1148e-02,\n",
      "            4.7953e-02, -6.8820e-02],\n",
      "          [-1.7381e-02, -2.1844e-04, -3.2790e-02,  ...,  4.2935e-02,\n",
      "           -3.7176e-02, -7.3082e-03]]]], requires_grad=True)\n",
      "\n",
      "Dequantized weights: \n",
      "tensor([[[[-0.0113,  0.0061,  0.0073,  ...,  0.0028,  0.0055,  0.0116],\n",
      "          [ 0.0138,  0.0131, -0.0046,  ...,  0.0018,  0.0128,  0.0128],\n",
      "          [ 0.0214,  0.0269,  0.0119,  ...,  0.0186,  0.0272,  0.0189],\n",
      "          ...,\n",
      "          [-0.0141,  0.0003,  0.0006,  ..., -0.0180, -0.0223, -0.0034],\n",
      "          [-0.0214, -0.0174, -0.0293,  ..., -0.0046, -0.0241, -0.0189],\n",
      "          [-0.0031,  0.0018, -0.0251,  ..., -0.0150, -0.0037, -0.0003]],\n",
      "\n",
      "         [[-0.0119, -0.0171, -0.0049,  ..., -0.0076, -0.0177, -0.0134],\n",
      "          [-0.0040, -0.0125, -0.0098,  ..., -0.0162, -0.0052, -0.0055],\n",
      "          [-0.0043, -0.0024, -0.0006,  ...,  0.0113, -0.0092,  0.0021],\n",
      "          ...,\n",
      "          [-0.0287, -0.0159, -0.0070,  ..., -0.0214, -0.0238, -0.0134],\n",
      "          [-0.0391, -0.0324, -0.0275,  ..., -0.0150, -0.0257, -0.0226],\n",
      "          [-0.0092, -0.0092, -0.0186,  ..., -0.0205, -0.0214, -0.0235]],\n",
      "\n",
      "         [[-0.0015, -0.0055, -0.0138,  ..., -0.0073, -0.0049, -0.0003],\n",
      "          [ 0.0116, -0.0101,  0.0037,  ..., -0.0101, -0.0024,  0.0000],\n",
      "          [-0.0009, -0.0043,  0.0101,  ...,  0.0018, -0.0034, -0.0076],\n",
      "          ...,\n",
      "          [ 0.0134,  0.0186,  0.0003,  ...,  0.0159,  0.0064,  0.0119],\n",
      "          [-0.0110, -0.0113, -0.0015,  ...,  0.0067,  0.0055,  0.0083],\n",
      "          [ 0.0128, -0.0046,  0.0095,  ...,  0.0034,  0.0006, -0.0012]]],\n",
      "\n",
      "\n",
      "        [[[-0.0014,  0.0038,  0.0023,  ..., -0.0014,  0.0039,  0.0078],\n",
      "          [ 0.0001,  0.0080,  0.0078,  ...,  0.0077, -0.0035,  0.0025],\n",
      "          [ 0.0027,  0.0006,  0.0063,  ...,  0.0093, -0.0001,  0.0034],\n",
      "          ...,\n",
      "          [-0.0011,  0.0079, -0.0011,  ...,  0.0033,  0.0063,  0.0028],\n",
      "          [-0.0015,  0.0003,  0.0048,  ..., -0.0004,  0.0084, -0.0038],\n",
      "          [-0.0032,  0.0044,  0.0085,  ...,  0.0034,  0.0064, -0.0003]],\n",
      "\n",
      "         [[ 0.0022, -0.0001, -0.0019,  ...,  0.0047,  0.0033, -0.0031],\n",
      "          [ 0.0033, -0.0030,  0.0009,  ..., -0.0024,  0.0017,  0.0015],\n",
      "          [ 0.0045, -0.0020,  0.0040,  ..., -0.0042,  0.0063, -0.0013],\n",
      "          ...,\n",
      "          [ 0.0043, -0.0071,  0.0056,  ..., -0.0002, -0.0007,  0.0053],\n",
      "          [ 0.0065, -0.0066, -0.0031,  ...,  0.0010, -0.0021,  0.0028],\n",
      "          [ 0.0031, -0.0051,  0.0033,  ...,  0.0042, -0.0022,  0.0078]],\n",
      "\n",
      "         [[ 0.0016,  0.0004,  0.0108,  ...,  0.0025,  0.0079,  0.0075],\n",
      "          [ 0.0062,  0.0071,  0.0040,  ...,  0.0042,  0.0086,  0.0091],\n",
      "          [ 0.0065,  0.0105,  0.0073,  ...,  0.0095,  0.0078,  0.0015],\n",
      "          ...,\n",
      "          [ 0.0056,  0.0085,  0.0119,  ...,  0.0052,  0.0128,  0.0063],\n",
      "          [ 0.0095,  0.0078,  0.0041,  ...,  0.0093,  0.0060,  0.0107],\n",
      "          [ 0.0018, -0.0004,  0.0085,  ...,  0.0102,  0.0045,  0.0084]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "          ...,\n",
      "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]],\n",
      "\n",
      "         [[ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "          ...,\n",
      "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]],\n",
      "\n",
      "         [[ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "          ...,\n",
      "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[-0.0090, -0.0101, -0.0013,  ...,  0.0041, -0.0154, -0.0122],\n",
      "          [ 0.0086,  0.0068,  0.0024,  ..., -0.0013,  0.0009, -0.0081],\n",
      "          [ 0.0066,  0.0047, -0.0122,  ..., -0.0113,  0.0034,  0.0011],\n",
      "          ...,\n",
      "          [-0.0079, -0.0009,  0.0034,  ..., -0.0002,  0.0047, -0.0004],\n",
      "          [ 0.0079,  0.0045, -0.0098,  ..., -0.0060, -0.0124, -0.0143],\n",
      "          [-0.0090,  0.0041, -0.0060,  ..., -0.0210, -0.0011, -0.0111]],\n",
      "\n",
      "         [[ 0.0015,  0.0043, -0.0006,  ..., -0.0047, -0.0180, -0.0158],\n",
      "          [-0.0101,  0.0068, -0.0113,  ...,  0.0036,  0.0053,  0.0105],\n",
      "          [ 0.0041,  0.0053, -0.0143,  ..., -0.0077, -0.0135,  0.0041],\n",
      "          ...,\n",
      "          [-0.0062,  0.0068,  0.0013,  ..., -0.0071, -0.0062,  0.0077],\n",
      "          [-0.0122, -0.0105,  0.0043,  ..., -0.0051, -0.0139, -0.0098],\n",
      "          [ 0.0009, -0.0045, -0.0056,  ..., -0.0030, -0.0148, -0.0098]],\n",
      "\n",
      "         [[ 0.0077,  0.0086, -0.0090,  ..., -0.0036, -0.0128, -0.0039],\n",
      "          [ 0.0184,  0.0107,  0.0250,  ...,  0.0237,  0.0242,  0.0116],\n",
      "          [ 0.0141,  0.0255,  0.0169,  ...,  0.0036,  0.0098,  0.0186],\n",
      "          ...,\n",
      "          [ 0.0216,  0.0096,  0.0075,  ...,  0.0098,  0.0116,  0.0167],\n",
      "          [ 0.0182,  0.0131,  0.0182,  ...,  0.0116,  0.0051,  0.0107],\n",
      "          [-0.0036,  0.0101,  0.0049,  ...,  0.0058,  0.0126,  0.0056]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0091,  0.0185,  0.0219,  ...,  0.0128,  0.0074,  0.0012],\n",
      "          [ 0.0190,  0.0084,  0.0202,  ...,  0.0192,  0.0076,  0.0138],\n",
      "          [ 0.0025,  0.0202,  0.0232,  ...,  0.0136,  0.0205,  0.0111],\n",
      "          ...,\n",
      "          [ 0.0140,  0.0027,  0.0071,  ..., -0.0025,  0.0205,  0.0067],\n",
      "          [-0.0173, -0.0113, -0.0067,  ..., -0.0027, -0.0062,  0.0099],\n",
      "          [-0.0044,  0.0052,  0.0052,  ..., -0.0071,  0.0076,  0.0000]],\n",
      "\n",
      "         [[ 0.0086,  0.0076,  0.0020,  ..., -0.0057,  0.0126,  0.0037],\n",
      "          [ 0.0044,  0.0005,  0.0020,  ..., -0.0012, -0.0032,  0.0015],\n",
      "          [-0.0067,  0.0054,  0.0035,  ...,  0.0084,  0.0096,  0.0089],\n",
      "          ...,\n",
      "          [-0.0059,  0.0123, -0.0069,  ..., -0.0042,  0.0131, -0.0071],\n",
      "          [-0.0035,  0.0025,  0.0067,  ..., -0.0081, -0.0015, -0.0089],\n",
      "          [-0.0140, -0.0022, -0.0035,  ..., -0.0059, -0.0017,  0.0005]],\n",
      "\n",
      "         [[-0.0042, -0.0025,  0.0015,  ...,  0.0015, -0.0064,  0.0049],\n",
      "          [ 0.0047,  0.0002, -0.0076,  ..., -0.0054,  0.0084,  0.0094],\n",
      "          [ 0.0054,  0.0015, -0.0062,  ...,  0.0059,  0.0039, -0.0010],\n",
      "          ...,\n",
      "          [ 0.0126, -0.0037, -0.0012,  ..., -0.0022,  0.0079, -0.0032],\n",
      "          [ 0.0017,  0.0005, -0.0165,  ...,  0.0012,  0.0030, -0.0027],\n",
      "          [ 0.0057, -0.0074, -0.0089,  ..., -0.0057,  0.0069, -0.0069]]],\n",
      "\n",
      "\n",
      "        [[[-0.0058, -0.0070, -0.0027,  ..., -0.0061, -0.0100, -0.0041],\n",
      "          [-0.0019,  0.0012, -0.0028,  ..., -0.0043, -0.0114, -0.0072],\n",
      "          [-0.0054, -0.0037, -0.0050,  ..., -0.0124, -0.0064, -0.0045],\n",
      "          ...,\n",
      "          [ 0.0010, -0.0099, -0.0114,  ..., -0.0014, -0.0066, -0.0064],\n",
      "          [-0.0078, -0.0023, -0.0004,  ..., -0.0101, -0.0092, -0.0018],\n",
      "          [-0.0039,  0.0008, -0.0087,  ...,  0.0015, -0.0056, -0.0051]],\n",
      "\n",
      "         [[ 0.0069, -0.0014,  0.0070,  ..., -0.0060, -0.0013, -0.0071],\n",
      "          [ 0.0018,  0.0078,  0.0010,  ..., -0.0001, -0.0026,  0.0008],\n",
      "          [ 0.0035,  0.0015, -0.0016,  ..., -0.0109, -0.0119,  0.0000],\n",
      "          ...,\n",
      "          [-0.0076, -0.0064, -0.0066,  ...,  0.0014, -0.0006,  0.0039],\n",
      "          [ 0.0025, -0.0076,  0.0013,  ..., -0.0061, -0.0039,  0.0020],\n",
      "          [-0.0018,  0.0002,  0.0026,  ..., -0.0003,  0.0026, -0.0018]],\n",
      "\n",
      "         [[-0.0039, -0.0053, -0.0022,  ..., -0.0018, -0.0055,  0.0035],\n",
      "          [ 0.0044, -0.0041,  0.0059,  ..., -0.0040,  0.0035, -0.0066],\n",
      "          [ 0.0056, -0.0034, -0.0050,  ...,  0.0004,  0.0024, -0.0049],\n",
      "          ...,\n",
      "          [-0.0029, -0.0021, -0.0030,  ..., -0.0063,  0.0003,  0.0007],\n",
      "          [-0.0053, -0.0047, -0.0027,  ...,  0.0009,  0.0037, -0.0053],\n",
      "          [-0.0013,  0.0000, -0.0025,  ...,  0.0033, -0.0029, -0.0006]]]])\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('Original weights: ')\n",
    "print(net.conv1.weight)  # Display only a small part of the weights for clarity\n",
    "print('')\n",
    "print('Dequantized weights: ')\n",
    "print(torch.dequantize(model_quantized.conv1.weight()))  # Display only a small part of the dequantized weights for clarity\n",
    "print('')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Print size and accuracy of the quantized model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of the model after quantization\n",
      "Size (KB): 11311.969\n"
     ]
    }
   ],
   "source": [
    "print('Size of the model after quantization')\n",
    "print_size_of_model(model_quantized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing the model after quantization\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing: 100%|██████████| 1000/1000 [00:05<00:00, 174.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.286\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "print('Testing the model after quantization')\n",
    "test(model_quantized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_FILENAME = \"model_quantized.pth\"\n",
    "\n",
    "model_quantized.load_state_dict(torch.load(MODEL_FILENAME))\n",
    "model_quantized.to(device)\n",
    "model_quantized.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Export the quantized model to ONNX format\n",
    "\n",
    "ONNX (Open Neural Network Exchange) is an open standard format for representing machine learning models. Converting PyTorch models to ONNX format enables interoperability across different frameworks and deployment platforms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kagad\\AppData\\Local\\Temp\\ipykernel_14800\\2785603295.py:4: DeprecationWarning: You are using the legacy TorchScript-based ONNX export. Starting in PyTorch 2.9, the new torch.export-based ONNX exporter will be the default. To switch now, set dynamo=True in torch.onnx.export. This new exporter supports features like exporting LLMs with DynamicCache. We encourage you to try it and share feedback to help improve the experience. Learn more about the new export logic: https://pytorch.org/docs/stable/onnx_dynamo.html. For exporting control flow: https://pytorch.org/tutorials/beginner/onnx/export_control_flow_model_to_onnx_tutorial.html.\n",
      "  torch.onnx.export(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Quantized model exported to ONNX format successfully!\n"
     ]
    }
   ],
   "source": [
    "# Convert the quantized model to ONNX format\n",
    "dummy_input = torch.randn(1, 3, 32, 32).to(device)\n",
    "\n",
    "torch.onnx.export(\n",
    "    model_quantized,\n",
    "    dummy_input,\n",
    "    \"model_quantized.onnx\",\n",
    "    export_params=True,\n",
    "    opset_version=13,  # Changed from 11 to 13 for quantized model support\n",
    "    do_constant_folding=True,\n",
    "    input_names=['input'],\n",
    "    output_names=['output'],\n",
    "    dynamic_axes={'input': {0: 'batch_size'},\n",
    "                  'output': {0: 'batch_size'}}\n",
    ")\n",
    "\n",
    "print(\"Quantized model exported to ONNX format successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ONNX model loaded successfully!\n",
      "Input name: input\n",
      "Input shape: ['batch_size', 3, 32, 32]\n",
      "Output name: output\n",
      "Output shape: ['batch_size', 10]\n"
     ]
    }
   ],
   "source": [
    "import onnxruntime as ort\n",
    "\n",
    "# Load the ONNX model\n",
    "ort_session = ort.InferenceSession(\"model_quantized.onnx\")\n",
    "\n",
    "print(\"ONNX model loaded successfully!\")\n",
    "print(f\"Input name: {ort_session.get_inputs()[0].name}\")\n",
    "print(f\"Input shape: {ort_session.get_inputs()[0].shape}\")\n",
    "print(f\"Output name: {ort_session.get_outputs()[0].name}\")\n",
    "print(f\"Output shape: {ort_session.get_outputs()[0].shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_onnx(ort_session, total_iterations: int = None) -> None:\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    iterations = 0\n",
    "\n",
    "    for data in tqdm(test_loader, desc='Testing ONNX model'):\n",
    "        x, y = data\n",
    "        x_numpy = x.numpy()  # Convert to numpy for ONNX runtime\n",
    "        \n",
    "        # Run inference with ONNX runtime\n",
    "        outputs = ort_session.run(None, {'input': x_numpy})\n",
    "        output = outputs[0]  # Get the output tensor\n",
    "        \n",
    "        # Convert back to torch tensor for easier handling\n",
    "        output = torch.from_numpy(output)\n",
    "        \n",
    "        for idx, i in enumerate(output):\n",
    "            if torch.argmax(i) == y[idx]:\n",
    "                correct += 1\n",
    "            total += 1\n",
    "        \n",
    "        iterations += 1\n",
    "        if total_iterations is not None and iterations >= total_iterations:\n",
    "            break\n",
    "    \n",
    "    print(f'ONNX Model Accuracy: {round(correct/total, 3)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing ONNX model: 100%|██████████| 1000/1000 [00:04<00:00, 233.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ONNX Model Accuracy: 0.285\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "test_onnx(ort_session=ort_session)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "INFERENCE SPEED COMPARISON\n",
      "============================================================\n",
      "PyTorch Model:    3.39 ± 3.17 ms\n",
      "ONNX Runtime:     0.85 ± 0.75 ms\n",
      "Speedup:          3.97x\n",
      "\n",
      "============================================================\n",
      "OUTPUT DIFFERENCE ANALYSIS\n",
      "============================================================\n",
      "Max absolute difference:  0.000000\n",
      "Mean absolute difference: 0.000000\n",
      "Are outputs close?:       True\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "\n",
    "def benchmark_pytorch_vs_onnx(pytorch_model, onnx_session, num_iterations=100):\n",
    "    \"\"\"\n",
    "    Compare inference speed between PyTorch model and ONNX runtime\n",
    "    \"\"\"\n",
    "    # Prepare test data\n",
    "    test_input = torch.randn(1, 3, 32, 32).to(device)\n",
    "    test_input_numpy = test_input.cpu().numpy()\n",
    "    \n",
    "    # Warm up runs\n",
    "    for _ in range(10):\n",
    "        with torch.no_grad():\n",
    "            _ = pytorch_model(test_input)\n",
    "        _ = onnx_session.run(None, {'input': test_input_numpy})\n",
    "    \n",
    "    # Benchmark PyTorch\n",
    "    pytorch_times = []\n",
    "    pytorch_model.eval()\n",
    "    \n",
    "    for _ in range(num_iterations):\n",
    "        start_time = time.time()\n",
    "        with torch.no_grad():\n",
    "            pytorch_output = pytorch_model(test_input)\n",
    "        end_time = time.time()\n",
    "        pytorch_times.append(end_time - start_time)\n",
    "    \n",
    "    # Benchmark ONNX\n",
    "    onnx_times = []\n",
    "    \n",
    "    for _ in range(num_iterations):\n",
    "        start_time = time.time()\n",
    "        onnx_output = onnx_session.run(None, {'input': test_input_numpy})\n",
    "        end_time = time.time()\n",
    "        onnx_times.append(end_time - start_time)\n",
    "    \n",
    "    # Calculate statistics\n",
    "    pytorch_avg = np.mean(pytorch_times) * 1000  # Convert to ms\n",
    "    pytorch_std = np.std(pytorch_times) * 1000\n",
    "    onnx_avg = np.mean(onnx_times) * 1000\n",
    "    onnx_std = np.std(onnx_times) * 1000\n",
    "    \n",
    "    # Compare outputs\n",
    "    pytorch_output_numpy = pytorch_output.cpu().numpy()\n",
    "    onnx_output_numpy = onnx_output[0]\n",
    "    \n",
    "    # Calculate differences\n",
    "    max_diff = np.max(np.abs(pytorch_output_numpy - onnx_output_numpy))\n",
    "    mean_diff = np.mean(np.abs(pytorch_output_numpy - onnx_output_numpy))\n",
    "    \n",
    "    print(\"=\" * 60)\n",
    "    print(\"INFERENCE SPEED COMPARISON\")\n",
    "    print(\"=\" * 60)\n",
    "    print(f\"PyTorch Model:    {pytorch_avg:.2f} ± {pytorch_std:.2f} ms\")\n",
    "    print(f\"ONNX Runtime:     {onnx_avg:.2f} ± {onnx_std:.2f} ms\")\n",
    "    print(f\"Speedup:          {pytorch_avg/onnx_avg:.2f}x\")\n",
    "    print()\n",
    "    print(\"=\" * 60)\n",
    "    print(\"OUTPUT DIFFERENCE ANALYSIS\")\n",
    "    print(\"=\" * 60)\n",
    "    print(f\"Max absolute difference:  {max_diff:.6f}\")\n",
    "    print(f\"Mean absolute difference: {mean_diff:.6f}\")\n",
    "    print(f\"Are outputs close?:       {np.allclose(pytorch_output_numpy, onnx_output_numpy, atol=1e-5)}\")\n",
    "    \n",
    "    return {\n",
    "        'pytorch_times': pytorch_times,\n",
    "        'onnx_times': onnx_times,\n",
    "        'pytorch_avg_ms': pytorch_avg,\n",
    "        'onnx_avg_ms': onnx_avg,\n",
    "        'speedup': pytorch_avg/onnx_avg,\n",
    "        'max_diff': max_diff,\n",
    "        'mean_diff': mean_diff\n",
    "    }\n",
    "\n",
    "# Run the benchmark\n",
    "results = benchmark_pytorch_vs_onnx(model_quantized, ort_session, num_iterations=100)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.12.10)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
